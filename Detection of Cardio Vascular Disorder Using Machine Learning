import kagglehub
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout

# Step 1: Download the Dataset
path = kagglehub.dataset_download("shayanfazeli/heartbeat")
print("Path to dataset files:", path)

# Load the Dataset
data_path = f"{path}/mitbih_train.csv"  # Adjust path to actual dataset file name
data = pd.read_csv(data_path, header=None)

# Step 2: Preprocess the Data
# The dataset has 188 columns, with the last column as the label
labels = data.iloc[:, -1]  # Extract the last column as the target labels
ecg_signals = data.iloc[:, :-1].values  # Drop the last column to get ECG data

# Train-Test Split and Standardization
X_train, X_test, y_train, y_test = train_test_split(ecg_signals, labels, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Reshape for CNN input (only for the deep learning model)
X_train_cnn = X_train[..., np.newaxis]
X_test_cnn = X_test[..., np.newaxis]

# Step 3: Build and Train Models

# Traditional Machine Learning: Random Forest
def extract_features(signal):
    return [np.mean(signal), np.std(signal), np.max(signal), np.min(signal)]

X_train_features = np.array([extract_features(x) for x in X_train])
X_test_features = np.array([extract_features(x) for x in X_test])

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_features, y_train)
y_pred_rf = rf_model.predict(X_test_features)

print("Random Forest Model")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

# Deep Learning Model: CNN
cnn_model = Sequential([
    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Conv1D(128, kernel_size=3, activation='relu'),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Change to 'softmax' and adjust output shape for multi-class
])

cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate CNN Model
y_pred_dl = (cnn_model.predict(X_test_cnn) > 0.5).astype("int32")
print("\nCNN Model")
print("Accuracy:", accuracy_score(y_test, y_pred_dl))
print("Classification Report:\n", classification_report(y_test, y_pred_dl))
